{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "path = 'E:/Repos/Cloud-Type-Identifier/Images/'\n",
    "with open(f'{path}types.json', 'r') as f:\n",
    "    classes = json.load(f)\n",
    "\n",
    "class_folders = [f'{path}{c}/' for c in classes]\n",
    "\n",
    "label2idx = {c: i for i, c in enumerate(classes)}\n",
    "idx2label = {i: c for i, c in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with all the image file paths and their labels\n",
    "df = pd.DataFrame(columns=['path', 'label'])\n",
    "\n",
    "for i, folder in enumerate(class_folders):\n",
    "    for file in os.listdir(folder):\n",
    "        df = df.append({'path': folder+file, 'label': i}, ignore_index=True)\n",
    "\n",
    "# Shuffle the df\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Split the df into train and test\n",
    "train_df = df.iloc[:int(len(df)*0.8)]\n",
    "test_df = df.iloc[int(len(df)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "train_transform = A.Compose([\n",
    "    A.SmallestMaxSize(300),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=360, p=0.5),\n",
    "    A.RandomCrop(height=224, width=224),\n",
    "    A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.MultiplicativeNoise(multiplier=[0.5, 2], per_channel=True, p=0.2),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.229, 0.225]),\n",
    "    A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.SmallestMaxSize(max_size=350),\n",
    "    A.CenterCrop(height=256, width=256),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['path']\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        label = self.df.iloc[idx]['label']\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)['image']\n",
    "\n",
    "        return img, label        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the datasets\n",
    "train_dataset = CloudDataset(train_df, transform=train_transform)\n",
    "test_dataset = CloudDataset(test_df, transform=test_transform)\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some images\n",
    "def visualize(dataset, samples=10, cols=5):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    viz_transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    dataset.transform = viz_transform # Remove the normalization and ToTensorV2 transforms\n",
    "\n",
    "    rows = samples//cols\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(12, 8))\n",
    "    for i in range(samples):\n",
    "        idx = np.random.randint(1, len(dataset))\n",
    "        img, label = dataset[idx]\n",
    "        ax.ravel()[i].imshow(img)\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "        ax.ravel()[i].set_title(idx2label[label])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "class CloudCNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(CloudCNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 1, 1), # 224x224x3 -> 224x224x32\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, 3, 1, 1), # 224x224x32 -> 224x224x64\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2), # 224x224x64 -> 112x112x64\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # 112x112x64 -> 112x112x128\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, 3, 1, 1), # 112x112x128 -> 112x112x128\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2), # 112x112x128 -> 56x56x128\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # 56x56x128 -> 56x56x256\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1), # 56x56x256 -> 56x56x256\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2), # 56x56x256 -> 28x28x256\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1), # 28x28x256 -> 28x28x512\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1), # 28x28x512 -> 28x28x512\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(2, 2), # 28x28x512 -> 14x14x512\n",
    "\n",
    "            nn.Flatten(), # 14x14x512 -> 100352\n",
    "            nn.Linear(100352, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds==labels).item()/len(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
